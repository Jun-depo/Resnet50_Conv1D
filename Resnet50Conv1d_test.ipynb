{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.engine.input_layer import Input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.utils import plot_model, to_categorical\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv1D, BatchNormalization\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "\n",
    "import random, os, sys\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.initializers import *\n",
    "import tensorflow as tf\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "pd.set_option('precision', 30)\n",
    "np.set_printoptions(precision = 30)\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../train.csv\", dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:,0]\n",
    "y = data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629145480,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629145480,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_ave_pooling(x_s, y_s, step_size=5):\n",
    "    # pooling a single data point to 1/10 of the original length\n",
    "    n = len(x_s)//step_size \n",
    "    \n",
    "    x_temp = x_s[0:n*step_size].reshape(-1, step_size)\n",
    "    x_ave = np.mean(x_temp, axis=1)\n",
    "    return x_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x, y, seq_length=150000, step_size=5, data_spread=10000):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x seq_length from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       seq_length: Number of encoded chars in a sequence\n",
    "    '''\n",
    "    n_data = len(x)//data_spread\n",
    "    \n",
    "    ## TODO: Get the number of batches we can make\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for n in range(n_data-14):\n",
    "\n",
    "        x_temp = x[n*data_spread:(n*data_spread + seq_length)]\n",
    "        y_temp = y[n*data_spread + seq_length-1]\n",
    "        \n",
    "        x_ave = x_ave_pooling(x_temp, step_size)\n",
    "        \n",
    "        x_data.append(x_ave)\n",
    "        y_data.append(y_temp)\n",
    "    return np.array(x_data), np.array(y_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = get_data(x, y, seq_length=150000, step_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62900, 30000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62900,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_exp = np.expand_dims(x_data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62900, 30000, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_exp= y_data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62900, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data_exp, y_data_exp, test_size=0.2, shuffle= True, random_state=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Resnet50Conv1d import identity_block, convolutional_block, ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jun4/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jun4/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 5999, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d_1 (ZeroPadding1D (None, 6005, 1)      0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv1D)                  (None, 3000, 64)     512         zero_padding1d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 3000, 64)     256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 3000, 64)     0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1499, 64)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv1D)         (None, 1499, 16)     1040        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1499, 16)     0           res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv1D)         (None, 1499, 16)     784         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1499, 16)     0           res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv1D)         (None, 1499, 64)     1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv1D)          (None, 1499, 64)     4160        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1499, 64)     0           res2a_branch2c[0][0]             \n",
      "                                                                 res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1499, 64)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv1D)         (None, 1499, 16)     1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1499, 16)     0           res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv1D)         (None, 1499, 16)     784         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1499, 16)     0           res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv1D)         (None, 1499, 64)     1088        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1499, 64)     0           res2b_branch2c[0][0]             \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1499, 64)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv1D)         (None, 1499, 16)     1040        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1499, 16)     0           res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv1D)         (None, 1499, 16)     784         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1499, 16)     0           res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv1D)         (None, 1499, 64)     1088        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1499, 64)     0           res2c_branch2c[0][0]             \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1499, 64)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv1D)         (None, 750, 32)      2080        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 750, 32)      0           res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv1D)         (None, 750, 32)      3104        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 750, 32)      0           res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv1D)         (None, 750, 128)     4224        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv1D)          (None, 750, 128)     8320        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 750, 128)     0           res3a_branch2c[0][0]             \n",
      "                                                                 res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 750, 128)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv1D)         (None, 750, 32)      4128        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 750, 32)      0           res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv1D)         (None, 750, 32)      3104        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 750, 32)      0           res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv1D)         (None, 750, 128)     4224        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 750, 128)     0           res3b_branch2c[0][0]             \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 750, 128)     0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv1D)         (None, 750, 32)      4128        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 750, 32)      0           res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv1D)         (None, 750, 32)      3104        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 750, 32)      0           res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv1D)         (None, 750, 128)     4224        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 750, 128)     0           res3c_branch2c[0][0]             \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 750, 128)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv1D)         (None, 750, 32)      4128        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 750, 32)      0           res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv1D)         (None, 750, 32)      3104        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 750, 32)      0           res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv1D)         (None, 750, 128)     4224        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 750, 128)     0           res3d_branch2c[0][0]             \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 750, 128)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv1D)         (None, 375, 64)      8256        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 375, 64)      0           res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv1D)         (None, 375, 64)      12352       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 375, 64)      0           res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv1D)         (None, 375, 256)     16640       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv1D)          (None, 375, 256)     33024       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 375, 256)     0           res4a_branch2c[0][0]             \n",
      "                                                                 res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 375, 256)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv1D)         (None, 375, 64)      16448       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 375, 64)      0           res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv1D)         (None, 375, 64)      12352       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 375, 64)      0           res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv1D)         (None, 375, 256)     16640       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 375, 256)     0           res4b_branch2c[0][0]             \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 375, 256)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv1D)         (None, 375, 64)      16448       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 375, 64)      0           res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv1D)         (None, 375, 64)      12352       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 375, 64)      0           res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv1D)         (None, 375, 256)     16640       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 375, 256)     0           res4c_branch2c[0][0]             \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 375, 256)     0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv1D)         (None, 375, 64)      16448       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 375, 64)      0           res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv1D)         (None, 375, 64)      12352       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 375, 64)      0           res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv1D)         (None, 375, 256)     16640       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 375, 256)     0           res4d_branch2c[0][0]             \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 375, 256)     0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv1D)         (None, 375, 64)      16448       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 375, 64)      0           res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv1D)         (None, 375, 64)      12352       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 375, 64)      0           res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv1D)         (None, 375, 256)     16640       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 375, 256)     0           res4e_branch2c[0][0]             \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 375, 256)     0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv1D)         (None, 375, 64)      16448       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 375, 64)      0           res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv1D)         (None, 375, 64)      12352       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 375, 64)      0           res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv1D)         (None, 375, 256)     16640       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 375, 256)     0           res4f_branch2c[0][0]             \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 375, 256)     0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv1D)         (None, 188, 64)      16448       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 188, 64)      0           res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv1D)         (None, 188, 64)      12352       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 188, 64)      0           res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv1D)         (None, 188, 256)     16640       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv1D)          (None, 188, 256)     65792       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 188, 256)     0           res5a_branch2c[0][0]             \n",
      "                                                                 res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 188, 256)     0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv1D)         (None, 188, 64)      16448       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 188, 64)      0           res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv1D)         (None, 188, 64)      12352       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 188, 64)      0           res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv1D)         (None, 188, 256)     16640       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 188, 256)     0           res5b_branch2c[0][0]             \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 188, 256)     0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv1D)         (None, 188, 64)      16448       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 188, 64)      0           res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv1D)         (None, 188, 64)      12352       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 188, 64)      0           res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv1D)         (None, 188, 256)     16640       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 188, 256)     0           res5c_branch2c[0][0]             \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 188, 256)     0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 37, 256)      0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9472)         0           average_pooling1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 9472)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc-dense (Dense)                (None, 1)            9473        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 574,817\n",
      "Trainable params: 574,689\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = ResNet50(\n",
    "    input_shape=(30000, 1), \n",
    "    n_out=1)\n",
    "#model = load_model() \n",
    "\n",
    "model.compile(\n",
    "    loss = \"mse\",\n",
    "    optimizer = Adam(lr=0.0001),\n",
    "    metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "epochs = 30\n",
    "\n",
    "# model = load_model('conv1d_length30000_batchNorm3.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jun4/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50320 samples, validate on 12580 samples\n",
      "Epoch 1/30\n",
      "50320/50320 [==============================] - 82s 2ms/step - loss: 58.1044 - mean_absolute_error: 3.5976 - val_loss: 8.3288 - val_mean_absolute_error: 2.2151\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.32877, saving model to ./Resnet50Conv1d_L2_model1_A/weights.001-8.329-2.215.hdf5\n",
      "Epoch 2/30\n",
      "50320/50320 [==============================] - 77s 2ms/step - loss: 8.9881 - mean_absolute_error: 2.3134 - val_loss: 7.9447 - val_mean_absolute_error: 2.1996\n",
      "\n",
      "Epoch 00002: val_loss improved from 8.32877 to 7.94468, saving model to ./Resnet50Conv1d_L2_model1_A/weights.002-7.945-2.200.hdf5\n",
      "Epoch 3/30\n",
      "50320/50320 [==============================] - 77s 2ms/step - loss: 8.4431 - mean_absolute_error: 2.2320 - val_loss: 8.7059 - val_mean_absolute_error: 2.1743\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 7.94468\n",
      "Epoch 4/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 8.2939 - mean_absolute_error: 2.2128 - val_loss: 7.8548 - val_mean_absolute_error: 2.1355\n",
      "\n",
      "Epoch 00004: val_loss improved from 7.94468 to 7.85484, saving model to ./Resnet50Conv1d_L2_model1_A/weights.004-7.855-2.135.hdf5\n",
      "Epoch 5/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 8.2268 - mean_absolute_error: 2.2046 - val_loss: 7.9127 - val_mean_absolute_error: 2.1356\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 7.85484\n",
      "Epoch 6/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 8.1825 - mean_absolute_error: 2.2011 - val_loss: 8.1652 - val_mean_absolute_error: 2.1401\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 7.85484\n",
      "Epoch 7/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 8.1486 - mean_absolute_error: 2.1959 - val_loss: 7.9732 - val_mean_absolute_error: 2.1367\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 7.85484\n",
      "Epoch 8/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 8.0010 - mean_absolute_error: 2.1787 - val_loss: 7.7363 - val_mean_absolute_error: 2.1267\n",
      "\n",
      "Epoch 00008: val_loss improved from 7.85484 to 7.73633, saving model to ./Resnet50Conv1d_L2_model1_A/weights.008-7.736-2.127.hdf5\n",
      "Epoch 9/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 8.0261 - mean_absolute_error: 2.1859 - val_loss: 7.7523 - val_mean_absolute_error: 2.1193\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 7.73633\n",
      "Epoch 10/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 7.9288 - mean_absolute_error: 2.1733 - val_loss: 7.5927 - val_mean_absolute_error: 2.1320\n",
      "\n",
      "Epoch 00010: val_loss improved from 7.73633 to 7.59266, saving model to ./Resnet50Conv1d_L2_model1_A/weights.010-7.593-2.132.hdf5\n",
      "Epoch 11/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 7.8250 - mean_absolute_error: 2.1573 - val_loss: 7.5207 - val_mean_absolute_error: 2.1218\n",
      "\n",
      "Epoch 00011: val_loss improved from 7.59266 to 7.52066, saving model to ./Resnet50Conv1d_L2_model1_A/weights.011-7.521-2.122.hdf5\n",
      "Epoch 12/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 7.7702 - mean_absolute_error: 2.1513 - val_loss: 7.5583 - val_mean_absolute_error: 2.0868\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 7.52066\n",
      "Epoch 13/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 7.5680 - mean_absolute_error: 2.1233 - val_loss: 7.3194 - val_mean_absolute_error: 2.0632\n",
      "\n",
      "Epoch 00013: val_loss improved from 7.52066 to 7.31942, saving model to ./Resnet50Conv1d_L2_model1_A/weights.013-7.319-2.063.hdf5\n",
      "Epoch 14/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 7.3189 - mean_absolute_error: 2.0856 - val_loss: 7.0336 - val_mean_absolute_error: 2.0661\n",
      "\n",
      "Epoch 00014: val_loss improved from 7.31942 to 7.03362, saving model to ./Resnet50Conv1d_L2_model1_A/weights.014-7.034-2.066.hdf5\n",
      "Epoch 15/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 6.9065 - mean_absolute_error: 2.0198 - val_loss: 6.4423 - val_mean_absolute_error: 1.9603\n",
      "\n",
      "Epoch 00015: val_loss improved from 7.03362 to 6.44229, saving model to ./Resnet50Conv1d_L2_model1_A/weights.015-6.442-1.960.hdf5\n",
      "Epoch 16/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 6.3822 - mean_absolute_error: 1.9342 - val_loss: 5.9532 - val_mean_absolute_error: 1.8395\n",
      "\n",
      "Epoch 00016: val_loss improved from 6.44229 to 5.95321, saving model to ./Resnet50Conv1d_L2_model1_A/weights.016-5.953-1.840.hdf5\n",
      "Epoch 17/30\n",
      "50320/50320 [==============================] - 76s 2ms/step - loss: 5.5797 - mean_absolute_error: 1.7979 - val_loss: 5.0768 - val_mean_absolute_error: 1.7125\n",
      "\n",
      "Epoch 00017: val_loss improved from 5.95321 to 5.07678, saving model to ./Resnet50Conv1d_L2_model1_A/weights.017-5.077-1.713.hdf5\n",
      "Epoch 18/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 4.8225 - mean_absolute_error: 1.6592 - val_loss: 4.3726 - val_mean_absolute_error: 1.5874\n",
      "\n",
      "Epoch 00018: val_loss improved from 5.07678 to 4.37261, saving model to ./Resnet50Conv1d_L2_model1_A/weights.018-4.373-1.587.hdf5\n",
      "Epoch 19/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 4.0574 - mean_absolute_error: 1.5186 - val_loss: 3.9858 - val_mean_absolute_error: 1.5042\n",
      "\n",
      "Epoch 00019: val_loss improved from 4.37261 to 3.98575, saving model to ./Resnet50Conv1d_L2_model1_A/weights.019-3.986-1.504.hdf5\n",
      "Epoch 20/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 3.4953 - mean_absolute_error: 1.4060 - val_loss: 4.3614 - val_mean_absolute_error: 1.6427\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.98575\n",
      "Epoch 21/30\n",
      "50320/50320 [==============================] - 79s 2ms/step - loss: 3.1117 - mean_absolute_error: 1.3289 - val_loss: 3.0873 - val_mean_absolute_error: 1.3269\n",
      "\n",
      "Epoch 00021: val_loss improved from 3.98575 to 3.08732, saving model to ./Resnet50Conv1d_L2_model1_A/weights.021-3.087-1.327.hdf5\n",
      "Epoch 22/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 2.6398 - mean_absolute_error: 1.2170 - val_loss: 2.5168 - val_mean_absolute_error: 1.1886\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.08732 to 2.51684, saving model to ./Resnet50Conv1d_L2_model1_A/weights.022-2.517-1.189.hdf5\n",
      "Epoch 23/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 2.3364 - mean_absolute_error: 1.1437 - val_loss: 2.3205 - val_mean_absolute_error: 1.1538\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.51684 to 2.32048, saving model to ./Resnet50Conv1d_L2_model1_A/weights.023-2.320-1.154.hdf5\n",
      "Epoch 24/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 2.1723 - mean_absolute_error: 1.1012 - val_loss: 1.7405 - val_mean_absolute_error: 0.9855\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.32048 to 1.74053, saving model to ./Resnet50Conv1d_L2_model1_A/weights.024-1.741-0.986.hdf5\n",
      "Epoch 25/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 2.0008 - mean_absolute_error: 1.0564 - val_loss: 1.6497 - val_mean_absolute_error: 0.9602\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.74053 to 1.64966, saving model to ./Resnet50Conv1d_L2_model1_A/weights.025-1.650-0.960.hdf5\n",
      "Epoch 26/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 1.8424 - mean_absolute_error: 1.0109 - val_loss: 1.6547 - val_mean_absolute_error: 0.9612\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.64966\n",
      "Epoch 27/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 1.5865 - mean_absolute_error: 0.9388 - val_loss: 1.8528 - val_mean_absolute_error: 1.0391\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.64966\n",
      "Epoch 28/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 1.4785 - mean_absolute_error: 0.9082 - val_loss: 1.5407 - val_mean_absolute_error: 0.9355\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.64966 to 1.54070, saving model to ./Resnet50Conv1d_L2_model1_A/weights.028-1.541-0.936.hdf5\n",
      "Epoch 29/30\n",
      "50320/50320 [==============================] - 78s 2ms/step - loss: 1.3788 - mean_absolute_error: 0.8788 - val_loss: 1.1779 - val_mean_absolute_error: 0.8045\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.54070 to 1.17794, saving model to ./Resnet50Conv1d_L2_model1_A/weights.029-1.178-0.804.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "50320/50320 [==============================] - 77s 2ms/step - loss: 1.2790 - mean_absolute_error: 0.8444 - val_loss: 1.3087 - val_mean_absolute_error: 0.8613\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.17794\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "    './Resnet50Conv1d_L2_model1_A/weights.{epoch:03d}-{val_loss:.3f}-{val_mean_absolute_error:.3f}.hdf5', \n",
    "    verbose=2, \n",
    "    save_best_only=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                    callbacks=[checkpointer], validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe3d8687e80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_title('mean_absolute_error')\n",
    "ax[1].plot(history.epoch, history.history[\"mean_absolute_error\"], label=\"Train mae\")\n",
    "ax[1].plot(history.epoch, history.history[\"val_mean_absolute_error\"], label=\"Validation mae\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_csv_file = './Resnet50Conv1d_L2_model1_A/weights.029-1.178-0.804_history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.328771281886746535860766016413</td>\n",
       "      <td>2.215086542593466489847742195707</td>\n",
       "      <td>58.104443138013394332119787577540</td>\n",
       "      <td>3.597627992432901766761688122642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.944681794389442330839301575907</td>\n",
       "      <td>2.199572227186921580255329899956</td>\n",
       "      <td>8.988114432500161399275384610519</td>\n",
       "      <td>2.313436588081154265950090120896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.705866491927251260563025425654</td>\n",
       "      <td>2.174321154608067185876052462845</td>\n",
       "      <td>8.443056220280537260691744450014</td>\n",
       "      <td>2.231954935965364317240755553939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.854836655269555656389002251672</td>\n",
       "      <td>2.135493017721251884921684904839</td>\n",
       "      <td>8.293865335309828168419699068181</td>\n",
       "      <td>2.212810104715805081809776311275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.912657871155366784421403281158</td>\n",
       "      <td>2.135584006210957674909423076315</td>\n",
       "      <td>8.226846895384674951401393627748</td>\n",
       "      <td>2.204607423955192491149546185625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           val_loss           val_mean_absolute_error  \\\n",
       "0  8.328771281886746535860766016413  2.215086542593466489847742195707   \n",
       "1  7.944681794389442330839301575907  2.199572227186921580255329899956   \n",
       "2  8.705866491927251260563025425654  2.174321154608067185876052462845   \n",
       "3  7.854836655269555656389002251672  2.135493017721251884921684904839   \n",
       "4  7.912657871155366784421403281158  2.135584006210957674909423076315   \n",
       "\n",
       "                                loss               mean_absolute_error  \n",
       "0  58.104443138013394332119787577540  3.597627992432901766761688122642  \n",
       "1   8.988114432500161399275384610519  2.313436588081154265950090120896  \n",
       "2   8.443056220280537260691744450014  2.231954935965364317240755553939  \n",
       "3   8.293865335309828168419699068181  2.212810104715805081809776311275  \n",
       "4   8.226846895384674951401393627748  2.204607423955192491149546185625  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv('./Resnet50Conv1d_L2_model1_A/weights.029-1.178-0.804_history.csv')\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = load_model('./Resnet50Conv1d_L2_model1_A/weights.029-1.178-0.804.hdf5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ave_pooling_x(x_s, step_size=5):\n",
    "    # pooling a single data point to 1/10 of the original length\n",
    "    n = len(x_s)//step_size \n",
    "    \n",
    "    x_temp = x_s[0:n*step_size].reshape(-1, step_size)    \n",
    "    x_ave = np.mean(x_temp, axis=1)    \n",
    "    return x_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('../test/' + \"seg_27de37.csv\")\n",
    "x = x['acoustic_data'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_resnet(x, load_model, step_size=5):\n",
    "    \n",
    "        arr_x = ave_pooling_x(x, step_size)\n",
    "        arr_x = np.expand_dims(arr_x, 1)\n",
    "        arr_x = np.expand_dims(arr_x, 0)\n",
    "        y_pred = load_model.predict(arr_x, batch_size=None, verbose=0, steps=None)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submission file\n",
    "submission = pd.read_csv('../sample_submission.csv', index_col='seg_id', dtype={\"time_to_failure\": np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seg_00030f</th>\n",
       "      <td>9.268905639648437500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_0012b5</th>\n",
       "      <td>4.291700363159179687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_00184e</th>\n",
       "      <td>6.128233909606933593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_003339</th>\n",
       "      <td>7.477239131927490234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_0042cc</th>\n",
       "      <td>5.315472602844238281250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time_to_failure\n",
       "seg_id                             \n",
       "seg_00030f  9.268905639648437500000\n",
       "seg_0012b5  4.291700363159179687500\n",
       "seg_00184e  6.128233909606933593750\n",
       "seg_003339  7.477239131927490234375\n",
       "seg_0042cc  5.315472602844238281250"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load each test data, create the feature matrix, get numeric prediction\n",
    "for i, seg_id in enumerate(submission.index):\n",
    "  #  print(i)\n",
    "    seg = pd.read_csv('../test/' + seg_id + '.csv')\n",
    "    x = seg['acoustic_data'].values\n",
    "    y = predict_resnet(x, load_model)\n",
    "    submission.time_to_failure[i] = y[-1,0].item()\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seg_ff4236</th>\n",
       "      <td>3.2771511077880859375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_ff7478</th>\n",
       "      <td>6.4921026229858398437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_ff79d9</th>\n",
       "      <td>2.5247814655303955078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_ffbd6a</th>\n",
       "      <td>7.1502723693847656250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_ffe7cc</th>\n",
       "      <td>6.2811017036437988281250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time_to_failure\n",
       "seg_id                              \n",
       "seg_ff4236  3.2771511077880859375000\n",
       "seg_ff7478  6.4921026229858398437500\n",
       "seg_ff79d9  2.5247814655303955078125\n",
       "seg_ffbd6a  7.1502723693847656250000\n",
       "seg_ffe7cc  6.2811017036437988281250"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./Resnet50Conv1d_L2_model1_A/Resnet50_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
